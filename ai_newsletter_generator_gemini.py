# -*- coding: utf-8 -*-
# pip install feedparser schedule python-dotenv openai langchain langchain-openai requests
import os
import smtplib
import feedparser
import schedule
import time
from datetime import datetime
from email.mime.text import MIMEText
from email.header import Header
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
import logging

# --- ì„¤ì • ---
# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()



# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# OpenAI API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logging.error("í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# Gmail ì„¤ì •
GMAIL_USER = os.getenv("GMAIL_USER") # ë³´ë‚´ëŠ” ì‚¬ëŒ Gmail ì£¼ì†Œ
GMAIL_PASSWORD = os.getenv("GMAIL_APP_PASSWORD") # Gmail ì•± ë¹„ë°€ë²ˆí˜¸
RECIPIENT_EMAILS = os.getenv("RECIPIENT_EMAILS", "").split(',') # ë°›ëŠ” ì‚¬ëŒ ì´ë©”ì¼ ì£¼ì†Œ (ì‰¼í‘œë¡œ êµ¬ë¶„)



if not GMAIL_USER or not GMAIL_PASSWORD or not RECIPIENT_EMAILS:
    logging.error("í™˜ê²½ë³€ìˆ˜ì—ì„œ Gmail ê´€ë ¨ ì„¤ì •(GMAIL_USER, GMAIL_APP_PASSWORD, RECIPIENT_EMAILS)ì„ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# ë°ì´í„° ì†ŒìŠ¤ (RSS í”¼ë“œ URL)
# í•„ìš”ì— ë”°ë¼ RSS í”¼ë“œ ì¶”ê°€/ìˆ˜ì •
RSS_FEEDS = {
    "GeekNews_AI": "https://news.hada.io/topic/ai.rss",
    # "PyTorch_Generative_AI": "https://discuss.pytorch.org/c/generative-ai/54.rss", # ì˜ˆì‹œ URL, ì‹¤ì œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸ í•„ìš”
    "Google AI Blog": "https://ai.googleblog.com/feeds/posts/default?alt=rss",
    "OpenAI Blog": "https://openai.com/blog/rss.xml",
    "DeepMind Blog": "https://deepmind.google/blog/rss.xml",
    "TechCrunch AI": "https://techcrunch.com/category/artificial-intelligence/feed/",
    "VentureBeat AI": "https://feeds.feedburner.com/venturebeat/ai",
    # ë‹¤ë¥¸ ì£¼ìš” ê¸°ìˆ  ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ AI ì„¹ì…˜ RSS ì¶”ê°€ ê°€ëŠ¥
}

# ë‰´ìŠ¤ ìš”ì•½ì— ì‚¬ìš©í•  LLM ëª¨ë¸
LLM_MODEL = "gpt-4o-mini" # ë˜ëŠ” "gpt-3.5-turbo" ë“±

# ë‰´ìŠ¤ë ˆí„° ì œëª©
NEWSLETTER_SUBJECT = f"ì˜¤ëŠ˜ì˜ AI ë™í–¥ ë‰´ìŠ¤ë ˆí„° ({datetime.now().strftime('%Y-%m-%d')})"

# í•œë²ˆì— ìš”ì•½í•  ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (API ë¹„ìš© ë° ì‹œê°„ ê´€ë¦¬)
MAX_ARTICLES_TO_SUMMARIZE = 20

# --- ê¸°ëŠ¥ í•¨ìˆ˜ ---

def fetch_rss_feeds(feed_urls):
    """ì§€ì •ëœ RSS í”¼ë“œ ëª©ë¡ì—ì„œ ìµœì‹  ë‰´ìŠ¤ í•­ëª©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    all_entries = []
    logging.info(f"{len(feed_urls)}ê°œì˜ RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    import ssl

    if hasattr(ssl, '_create_unverified_context'):
        ssl._create_default_https_context = ssl._create_unverified_context

    for name, url in feed_urls.items():
        try:
            feed = feedparser.parse(url)
            if feed.bozo: # feedparserê°€ íŒŒì‹± ì˜¤ë¥˜ë¥¼ ê°ì§€í–ˆì„ ë•Œ
                 logging.warning(f"'{name}' í”¼ë“œ íŒŒì‹± ì¤‘ ë¬¸ì œ ë°œìƒ (URL: {url}): {feed.bozo_exception}")
                 continue
            logging.info(f"'{name}' í”¼ë“œì—ì„œ {len(feed.entries)}ê°œ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ.")
            for entry in feed.entries:
                # ê°„ë‹¨í•œ ì •ë³´ë§Œ ì¶”ì¶œ (ì œëª©, ë§í¬, ë°œí–‰ì¼ - ì¡´ì¬í•  ê²½ìš°)
                published_time = entry.get('published_parsed') or entry.get('updated_parsed')
                entry_data = {
                    'title': entry.title,
                    'link': entry.link,
                    'published': time.strftime('%Y-%m-%d %H:%M:%S', published_time) if published_time else 'N/A',
                    'source': name
                }
                # ê°„ë‹¨í•œ ì¤‘ë³µ ì œê±° (ì œëª©ê³¼ ë§í¬ ê¸°ì¤€) - ë” ì •êµí•œ ë°©ë²• í•„ìš”ì‹œ ê°œì„ 
                if not any(e['title'] == entry_data['title'] and e['link'] == entry_data['link'] for e in all_entries):
                     all_entries.append(entry_data)

        except Exception as e:
            logging.error(f"'{name}' í”¼ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (URL: {url}): {e}")
    logging.info(f"ì´ {len(all_entries)}ê°œì˜ ê³ ìœ  ë‰´ìŠ¤ í•­ëª© ìˆ˜ì§‘ ì™„ë£Œ.")
    # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (ë°œí–‰ì¼ ê¸°ì¤€, 'N/A'ëŠ” ë’¤ë¡œ)
    all_entries.sort(key=lambda x: x['published'] if x['published'] != 'N/A' else '0000-00-00 00:00:00', reverse=True)
    return all_entries

def summarize_news_with_langchain(articles):
    """Langchainê³¼ OpenAI LLMì„ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    if not articles:
        logging.info("ìš”ì•½í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return "ìš”ì•½í•  ìµœì‹  AI ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."

    logging.info(f"{len(articles)}ê°œ ê¸°ì‚¬ ìš”ì•½ ì‹œì‘ (ëª¨ë¸: {LLM_MODEL})...")
    try:
        del os.environ['HTTP_PROXY']
        del os.environ['HTTPS_PROXY']
    except:
        pass

    # Langchain ì„¤ì •
    llm = ChatOpenAI(temperature=0.3, model_name=LLM_MODEL, openai_api_key=OPENAI_API_KEY)


    system_template = """
    ë‹¹ì‹ ì€ AI ê¸°ìˆ  ì „ë¬¸ ë‰´ìŠ¤ë ˆí„° ì—ë””í„°ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ AI ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì •ë¦¬ëœ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    **ì¤‘ìš”: ë‰´ìŠ¤ë ˆí„°ì˜ ëª¨ë“  ì •ë³´ëŠ” ì œê³µëœ ê¸°ì‚¬ ë‚´ìš©ì— ì—„ê²©íˆ ê¸°ë°˜í•´ì•¼ í•˜ë©°, ê²€ì¦ ê°€ëŠ¥í•œ ì‚¬ì‹¤ë§Œì„ í¬í•¨í•˜ê³  ê°€ì¥ ìµœì‹ ì˜ ë‰´ìŠ¤ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  ì£¼ì¥ì€ ê¸°ì‚¬ ë‚´ìš©ìœ¼ë¡œ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.**

    ë‰´ìŠ¤ë ˆí„° ìš”êµ¬ì‚¬í•­:
    1. ì¸íŠ¸ë¡œ: AI ê¸°ìˆ  ë™í–¥ì„ ê°„ëµí•˜ê²Œ ì†Œê°œí•˜ëŠ” ì¸ì‚¬ë§ (2-3ë¬¸ì¥). ìµœì‹  í•µì‹¬ íŠ¸ë Œë“œë¥¼ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
    2. ë‹¤ìŒ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„± (í•„ìš”ì‹œ ë‰´ìŠ¤ ë‚´ìš©ì— ë”°ë¼ ì„¹ì…˜ëª… ë° êµ¬ì„±ì€ ìœ ì—°í•˜ê²Œ ì¡°ì • ê°€ëŠ¥):
       - LLM ëª¨ë¸ ìµœì‹  ë™í–¥: ìµœì‹  ì–¸ì–´ ëª¨ë¸ ê´€ë ¨ ì£¼ìš” ì†Œì‹ (ì˜ˆ: ìƒˆë¡œìš´ ëª¨ë¸ ì¶œì‹œ, ì£¼ìš” ì—…ë°ì´íŠ¸, í˜ì‹ ì  ì—°êµ¬ ê²°ê³¼).
       - AI ì—ì´ì „íŠ¸ ê¸°ìˆ : ììœ¨ ì—ì´ì „íŠ¸, ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸, ë„êµ¬ ì‚¬ìš©(tool use) ë“± ê´€ë ¨ ê¸°ìˆ ì˜ ë°œì „ ì‚¬í•­.
       - ì£¼ìš” AI ê¸°ì—… ì†Œì‹: ì£¼ìš” AI ê¸°ì—…ë“¤(ì˜ˆ: OpenAI, Google DeepMind, Microsoft, Meta AI ë“±)ì˜ ì‹ ì œí’ˆ, ì£¼ìš” ì—°êµ¬ ë°œí‘œ, ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ë³€í™” ë“±.
       - AI í”„ë ˆì„ì›Œí¬ ë° ë„êµ¬ ì—…ë°ì´íŠ¸: PyTorch, TensorFlow, LangChain, Hugging Face ë“± ì£¼ìš” í”„ë ˆì„ì›Œí¬ ë° ê°œë°œ ë„êµ¬ ê´€ë ¨ ì¤‘ìš” ì—…ë°ì´íŠ¸ ì†Œì‹.
    3. ê° ì„¹ì…˜ì—ëŠ” ê°€ì¥ ì¤‘ìš”í•˜ê³  ìµœì‹ ì¸ ë‰´ìŠ¤ 3-5ê°œë¥¼ ì„ ë³„í•˜ì—¬ ìš”ì•½í•©ë‹ˆë‹¤. ë‹¨ìˆœ ìš”ì•½ì„ ë„˜ì–´, í•´ë‹¹ ë‰´ìŠ¤ê°€ ê°€ì§€ëŠ” ì˜ë¯¸, **í¥ë¯¸ë¡œìš´ í†µì°°ì´ë‚˜ ì£¼ëª©í•  ë§Œí•œ íŠ¸ë Œë“œë¥¼ í¬í•¨ì‹œí‚¤ë˜, ì´ëŸ¬í•œ ë¶„ì„ì´ë‚˜ í†µì°°ì€ ë°˜ë“œì‹œ ì›ë³¸ ê¸°ì‚¬ì˜ ë‚´ìš©ì— ì˜í•´ ëª…í™•íˆ ë’·ë°›ì¹¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.**
    4. ë§ˆë¬´ë¦¬: ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë™í–¥ì„ ê°„ëµíˆ ìš”ì•½í•˜ê³ , ë…ìë“¤ì´ ì£¼ëª©í•´ì•¼ í•  ë¯¸ë˜ ì „ë§ì´ë‚˜ ì§§ì€ ì œì–¸ì„ í¬í•¨í•˜ì—¬ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
    5. ì „ì²´ ë‰´ìŠ¤ë ˆí„° ë¶„ëŸ‰ì€ í•œê¸€ 1500-2000ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    6. ì „ë¬¸ì ì´ë©´ì„œë„ AI ë¶„ì•¼ì— ìµìˆ™í•˜ì§€ ì•Šì€ ë…ìë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ëª…í™•í•˜ê³  ê°„ê²°í•œ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
    7. HTML í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì „ì²´ ì œëª©ì€ <h1>, ë‰´ìŠ¤ë ˆí„°ì˜ ì£¼ìš” ì„¹ì…˜ ì œëª©ì€ <h2>, ê° ë‰´ìŠ¤ ìš”ì•½ì˜ ì†Œì œëª©ì€ <h3> íƒœê·¸ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”. ê° ë‰´ìŠ¤ ìš”ì•½ í›„ì—ëŠ” ì›ë¬¸ ê¸°ì‚¬ë¡œ ì—°ê²°ë˜ëŠ” í•˜ì´í¼ë§í¬ë¥¼ ëª…í™•íˆ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: `<a href='ê¸°ì‚¬ë§í¬'>ì›ë¬¸ë³´ê¸°</a>`).
    8. **ì •í™•í•œ ì¶œì²˜ ì¸ìš©ì€ íˆ¬ëª…ì„±ê³¼ ì •ë³´ ê²€ì¦ì— ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.** ê° ë‰´ìŠ¤ ìš”ì•½ ë§ë¯¸ì—ëŠ” ë°˜ë“œì‹œ ì›ë¬¸ ì¶œì²˜(ì†ŒìŠ¤ëª…)ì™€ í•¨ê»˜ ìœ„ì—ì„œ ì–¸ê¸‰ëœ 'ì›ë¬¸ë³´ê¸°' ë§í¬ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
    9. ë…ìë“¤ì˜ í¥ë¯¸ë¥¼ ìœ ë°œí•˜ê³  ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•´, ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ì´ëª¨ì§€(emoji)ë¥¼ ë¬¸ë§¥ì— ë§ê²Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”. (ì˜ˆ: ğŸš€ğŸ’¡ğŸ”¬ğŸ¤–)
    """

    # ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt_template = ChatPromptTemplate.from_messages(
        [
            ("system", system_template),
            ("human", "ë‹¤ìŒì€ ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ AI ê´€ë ¨ ë‰´ìŠ¤ ëª©ë¡ì…ë‹ˆë‹¤:\n\n{news_list}\n\nìœ„ ëª©ë¡ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ AI ë‰´ìŠ¤ë ˆí„° ë³¸ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ")
        ]
    )

    # ê¸°ì‚¬ ëª©ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
    news_list_str = ""
    for i, article in enumerate(articles):
        news_list_str += f"{i+1}. ì œëª©: {article['title']}\n   ë§í¬: {article['link']}\n   ì¶œì²˜: {article['source']}\n\n"


    # Langchain ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
    # RunnablePassthroughë¥¼ ì‚¬ìš©í•˜ì—¬ news_listë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì „ë‹¬
    # StrOutputParser()ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì˜ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ íŒŒì‹±
    chain = {"news_list": RunnablePassthrough()} | prompt_template | llm | StrOutputParser()

    try:
        # invoke ë©”ì†Œë“œì— news_list_str ì§ì ‘ ì „ë‹¬
        summary = chain.invoke(news_list_str)
        logging.info("ë‰´ìŠ¤ ìš”ì•½ ë° ë‰´ìŠ¤ë ˆí„° ì´ˆì•ˆ ìƒì„± ì™„ë£Œ.")
        summary = summary.replace("\n","<br>")
        return summary
    except Exception as e:
        logging.error(f"OpenAI API í˜¸ì¶œ ë˜ëŠ” Langchain ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"ë‰´ìŠ¤ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


def send_email(subject, body, recipient_emails):
    """Gmailì„ ì‚¬ìš©í•˜ì—¬ ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤."""
    if not recipient_emails or not recipient_emails[0]:
         logging.warning("ìˆ˜ì‹ ì ì´ë©”ì¼ ì£¼ì†Œê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì´ë©”ì¼ì„ ë°œì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
         return

    msg = MIMEText(body, 'plain', 'utf-8') # ë³¸ë¬¸ì„ UTF-8ë¡œ ì¸ì½”ë”©
    msg['Subject'] = Header(subject, 'utf-8') # ì œëª©ì„ UTF-8ë¡œ ì¸ì½”ë”©
    msg['From'] = GMAIL_USER
    msg['To'] = ", ".join(recipient_emails) # ì—¬ëŸ¬ ìˆ˜ì‹ ì ì²˜ë¦¬

    logging.info(f"'{', '.join(recipient_emails)}' ì£¼ì†Œë¡œ ì´ë©”ì¼ ë°œì†¡ ì‹œë„...")
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp_server:
            smtp_server.login(GMAIL_USER, GMAIL_PASSWORD)
            smtp_server.sendmail(GMAIL_USER, recipient_emails, msg.as_string())
        logging.info("ì´ë©”ì¼ ë°œì†¡ ì„±ê³µ!")
    except smtplib.SMTPAuthenticationError:
        # logging.error("Gmail ë¡œê·¸ì¸ ì‹¤íŒ¨. ì´ë©”ì¼ ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        # logging.error("2ë‹¨ê³„ ì¸ì¦ ì‚¬ìš© ì‹œ 'ì•± ë¹„ë°€ë²ˆí˜¸'ë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.")
        print("Gmail ë¡œê·¸ì¸ ì‹¤íŒ¨. ì´ë©”ì¼ ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        # logging.error(f"ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ì´ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def create_and_send_newsletter():
    """ë‰´ìŠ¤ ìˆ˜ì§‘, ìš”ì•½, ì´ë©”ì¼ ë°œì†¡ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    logging.info("AI ë‰´ìŠ¤ë ˆí„° ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")

    # 1. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
    news_items = fetch_rss_feeds(RSS_FEEDS)

    # 2. ìš”ì•½í•  ê¸°ì‚¬ ì„ íƒ (ìµœì‹  Nê°œ)
    articles_to_summarize = news_items[:MAX_ARTICLES_TO_SUMMARIZE]

    # 3. LLMì„ ì´ìš©í•œ ë‰´ìŠ¤ ìš”ì•½ ë° ë‰´ìŠ¤ë ˆí„° ë³¸ë¬¸ ìƒì„±
    newsletter_body = summarize_news_with_langchain(articles_to_summarize)

    # 4. ì´ë©”ì¼ ë°œì†¡
    send_email(NEWSLETTER_SUBJECT, newsletter_body, RECIPIENT_EMAILS)

    logging.info("AI ë‰´ìŠ¤ë ˆí„° ìƒì„± ë° ë°œì†¡ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")


# --- ìŠ¤ì¼€ì¤„ë§ ë° ì‹¤í–‰ ---

if __name__ == "__main__":
    logging.info("AI ë‰´ìŠ¤ë ˆí„° ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘.")
    logging.info(f"ë‰´ìŠ¤ë ˆí„°ëŠ” ë§¤ì¼ ì§€ì •ëœ ì‹œê°„ì— ë°œì†¡ë©ë‹ˆë‹¤.")
    logging.info(f"ìˆ˜ì‹ ì: {', '.join(RECIPIENT_EMAILS)}")


    # ìµœì´ˆ ì‹¤í–‰ ì‹œ í•œë²ˆ ì¦‰ì‹œ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ ë° ì¦‰ì‹œ í™•ì¸ìš©)
    logging.info("ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    create_and_send_newsletter()
    logging.info("ì´ˆê¸° ì‹¤í–‰ ì™„ë£Œ. ìŠ¤ì¼€ì¤„ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜í•©ë‹ˆë‹¤.")

    # ìŠ¤ì¼€ì¤„ ì„¤ì • (ë§¤ì¼ ì˜¤ì „ 8ì‹œì— ì‹¤í–‰) - ì‹œê°„ì€ í•„ìš”ì— ë”°ë¼ ë³€ê²½
    schedule.every().day.at("08:00").do(create_and_send_newsletter)



    while True:
        schedule.run_pending()
        time.sleep(60) # 1ë¶„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ í™•ì¸
